{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP1bkWX3jlomGayLeDqHWfR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swk16/week-1-/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2uL9Bq2f2odR"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import numpy             as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle           "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = '全唐诗.txt'"
      ],
      "metadata": {
        "id": "SXGPRNdI2qP3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(filename, 'rb')\n",
        "for i in range(0, 1000):\n",
        "    line = str(f.readline(), \"cp936\")\n",
        "    print (len(line))\n",
        "   \n",
        "f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyUKSyAh2vAL",
        "outputId": "ff1ee51b-e4aa-4ac2-8cbb-6d94f98d61bb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "2\n",
            "18\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "2\n",
            "17\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "2\n",
            "15\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "2\n",
            "17\n",
            "2\n",
            "26\n",
            "26\n",
            "27\n",
            "26\n",
            "26\n",
            "2\n",
            "15\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "2\n",
            "17\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "15\n",
            "2\n",
            "15\n",
            "2\n",
            "26\n",
            "26\n",
            "15\n",
            "2\n",
            "15\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "15\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "26\n",
            "15\n",
            "2\n",
            "37\n",
            "2\n",
            "26\n",
            "26\n",
            "15\n",
            "2\n",
            "20\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "2\n",
            "17\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "15\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "15\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "2\n",
            "15\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "2\n",
            "22\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "17\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "26\n",
            "15\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "15\n",
            "2\n",
            "18\n",
            "2\n",
            "26\n",
            "26\n",
            "15\n",
            "2\n",
            "15\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "2\n",
            "19\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "18\n",
            "2\n",
            "26\n",
            "26\n",
            "15\n",
            "2\n",
            "19\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "17\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "15\n",
            "2\n",
            "26\n",
            "26\n",
            "15\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "26\n",
            "2\n",
            "15\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "20\n",
            "2\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "20\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "17\n",
            "2\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "17\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "17\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "18\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "18\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "17\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "19\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "17\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "17\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "15\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "18\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "15\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "22\n",
            "2\n",
            "26\n",
            "26\n",
            "15\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "26\n",
            "15\n",
            "2\n",
            "15\n",
            "2\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "19\n",
            "2\n",
            "26\n",
            "26\n",
            "19\n",
            "2\n",
            "22\n",
            "2\n",
            "27\n",
            "2\n",
            "16\n",
            "2\n",
            "27\n",
            "2\n",
            "27\n",
            "2\n",
            "14\n",
            "2\n",
            "27\n",
            "2\n",
            "19\n",
            "2\n",
            "27\n",
            "2\n",
            "17\n",
            "2\n",
            "27\n",
            "2\n",
            "17\n",
            "2\n",
            "27\n",
            "2\n",
            "19\n",
            "2\n",
            "27\n",
            "2\n",
            "15\n",
            "2\n",
            "27\n",
            "2\n",
            "15\n",
            "2\n",
            "27\n",
            "2\n",
            "15\n",
            "2\n",
            "27\n",
            "2\n",
            "16\n",
            "2\n",
            "27\n",
            "2\n",
            "18\n",
            "2\n",
            "27\n",
            "2\n",
            "16\n",
            "2\n",
            "28\n",
            "2\n",
            "19\n",
            "2\n",
            "15\n",
            "15\n",
            "16\n",
            "15\n",
            "15\n",
            "2\n",
            "13\n",
            "2\n",
            "15\n",
            "2\n",
            "15\n",
            "2\n",
            "14\n",
            "2\n",
            "8\n",
            "6\n",
            "2\n",
            "22\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "17\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "13\n",
            "2\n",
            "26\n",
            "26\n",
            "15\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "15\n",
            "2\n",
            "19\n",
            "2\n",
            "26\n",
            "26\n",
            "15\n",
            "2\n",
            "15\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "12\n",
            "2\n",
            "26\n",
            "26\n",
            "15\n",
            "2\n",
            "21\n",
            "2\n",
            "20\n",
            "2\n",
            "23\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "18\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "18\n",
            "2\n",
            "26\n",
            "26\n",
            "19\n",
            "2\n",
            "26\n",
            "2\n",
            "14\n",
            "14\n",
            "15\n",
            "14\n",
            "14\n",
            "14\n",
            "15\n",
            "14\n",
            "14\n",
            "15\n",
            "14\n",
            "15\n",
            "14\n",
            "15\n",
            "15\n",
            "17\n",
            "2\n",
            "36\n",
            "2\n",
            "14\n",
            "14\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "14\n",
            "14\n",
            "15\n",
            "15\n",
            "15\n",
            "15\n",
            "16\n",
            "2\n",
            "19\n",
            "2\n",
            "26\n",
            "26\n",
            "19\n",
            "2\n",
            "19\n",
            "2\n",
            "26\n",
            "26\n",
            "18\n",
            "2\n",
            "8\n",
            "6\n",
            "2\n",
            "17\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "32\n",
            "2\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "27\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "15\n",
            "2\n",
            "20\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "20\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "15\n",
            "2\n",
            "18\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "22\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "15\n",
            "2\n",
            "15\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "17\n",
            "2\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "17\n",
            "2\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "20\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "19\n",
            "2\n",
            "15\n",
            "2\n",
            "26\n",
            "26\n",
            "22\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "19\n",
            "2\n",
            "21\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "22\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "21\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "36\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "19\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "18\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "17\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "17\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "19\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "18\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "18\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "20\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "23\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "20\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "25\n",
            "2\n",
            "26\n",
            "27\n",
            "2\n",
            "24\n",
            "2\n",
            "26\n",
            "26\n",
            "19\n",
            "2\n",
            "29\n",
            "2\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "36\n",
            "2\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "23\n",
            "2\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "32\n",
            "2\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "25\n",
            "2\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "17\n",
            "2\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "20\n",
            "2\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "19\n",
            "2\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "24\n",
            "2\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "19\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "16\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "36\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "20\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "14\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "17\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "17\n",
            "2\n",
            "26\n",
            "26\n",
            "26\n",
            "26\n",
            "27\n",
            "2\n",
            "17\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test some special characters\n",
        "special = [u'\\u3010', u'\\u3011'] ##'【' & '】'\n",
        "f = open(filename, 'rb')\n",
        "for i in range(0, 3):\n",
        "    line = str(f.readline(), \"cp936\")\n",
        "f.close()\n",
        "print (line)\n",
        "print (line[12])\n",
        "print (re.search(u'\\u3010', line).group(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwZcCXZn2xtJ",
        "outputId": "392135c8-000d-44fb-ba29-e10a721f91b9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "　　卷1_1【帝京篇十首】李世民\r\n",
            "\n",
            "】\n",
            "【\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_lines(old_line, line, poems):\n",
        "    #print line\n",
        "    if len(line) < 12 or re.search(u'\\u3010', line) is not None:\n",
        "        '''If this line is blank or title'''\n",
        "        old_line = ''\n",
        "    elif old_line == '':\n",
        "        '''If start a new line'''\n",
        "        poems.append(line[0:-2])\n",
        "        old_line = line\n",
        "    else:\n",
        "        '''If continuing to last poem'''\n",
        "        poems[-1] = poems[-1]+line[0:-2]\n",
        "        old_line = line\n",
        "    return poems, old_line"
      ],
      "metadata": {
        "id": "Z5K_Thw325fn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Reading txt file...\")\n",
        "poems = []\n",
        "old_line = ''\n",
        "with open(filename, 'rb') as f:\n",
        "    while True:\n",
        "        try:\n",
        "            line = str(f.readline(), \"cp936\")\n",
        "        except:\n",
        "            continue\n",
        "            \n",
        "        if not line:\n",
        "            break\n",
        "            \n",
        "        poems, old_line = add_lines(old_line, line, poems)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K-LDdoF28K7",
        "outputId": "13efa965-2026-4362-9b1d-ab5833a184af"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading txt file...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Amount is\",len(poems))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVW0333r2-hF",
        "outputId": "eb306d4c-a1f6-448d-d9d8-5940ff9ddcdf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount is 48975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 10):\n",
        "    print (poems[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6X9YOYF3BE5",
        "outputId": "1924320b-e020-4131-d326-2d56cd58432f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "秦川雄帝宅，函谷壮皇居。绮殿千寻起，离宫百雉馀。连薨遥接汉，飞观迥凌虚。云日隐层阙，风烟出绮疏。\n",
            "岩廊罢机务，崇文聊驻辇。玉匣启龙图，金绳披凤篆。韦编断仍续，缥帙舒还卷。对此乃淹留，欹案观坟典。\n",
            "移步出词林，停舆欣武宴。雕弓写明月，骏马疑流电。惊雁落虚弦，啼猿悲急箭。阅赏诚多美，于兹乃忘倦。\n",
            "鸣笳临乐馆，眺听欢芳节。急管韵朱弦，清歌凝白雪。彩凤肃来仪，玄鹤纷成列。去兹郑卫声，雅音方可悦。\n",
            "芳辰追逸趣，禁苑信多奇。桥形通汉上，峰势接云危。烟霞交隐映，花鸟自参差。何如肆辙迹，万里赏瑶池。\n",
            "飞盖去芳园，兰桡游翠渚。萍间日彩乱，荷处香风举。桂楫满中川，弦歌振长屿。岂必汾河曲，方为欢宴所。\n",
            "落日双阙昏，回舆九重暮。长烟散初碧，皎月澄轻素。搴幌玩琴书，开轩引云雾。斜汉耿层阁，清风摇玉树。\n",
            "欢乐难再逢，芳辰良可惜。玉酒泛云罍，兰殽陈绮席。千钟合尧禹，百兽谐金石。得志重寸阴，忘怀轻尺璧。\n",
            "建章欢赏夕，二八尽妖妍。罗绮昭阳殿，芬芳玳瑁筵。佩移星正动，扇掩月初圆。无劳上悬圃，即此对神仙。\n",
            "以兹游观极，悠然独长想。披卷览前踪，抚躬寻既往。望古茅茨约，瞻今兰殿广。人道恶高危，虚心戒盈荡。奉天竭诚敬，临民思惠养。纳善察忠谏，明科慎刑赏。六五诚难继，四三非易仰。广待淳化敷，方嗣云亭响。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(poem):\n",
        "    # poem_tokenize = [u'poem_start']\n",
        "    poem_tokenize = []\n",
        "    poem_tokenize.extend([poem[i] for i in range(0, len(poem))])\n",
        "    # poem_tokenize.append(u'poem_end')\n",
        "    return poem_tokenize\n",
        "poems_tokenize = [tokenize(poems[i]) for i in range(0, len(poems))]\n",
        "print (poems_tokenize[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yk9VLKtf3D7c",
        "outputId": "20a3f3e7-885d-4598-f245-adc819c62157"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['秦', '川', '雄', '帝', '宅', '，', '函', '谷', '壮', '皇', '居', '。', '绮', '殿', '千', '寻', '起', '，', '离', '宫', '百', '雉', '馀', '。', '连', '薨', '遥', '接', '汉', '，', '飞', '观', '迥', '凌', '虚', '。', '云', '日', '隐', '层', '阙', '，', '风', '烟', '出', '绮', '疏', '。']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poems[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vZcOYQH23GLE",
        "outputId": "39ccb32d-fd26-47ce-f702-9e5c18f5fb6f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'秦川雄帝宅，函谷壮皇居。绮殿千寻起，离宫百雉馀。连薨遥接汉，飞观迥凌虚。云日隐层阙，风烟出绮疏。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (len(poems[0]))\n",
        "poems[0][47]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "kWO5GaL_3V76",
        "outputId": "76b7ddd6-9bf7-448b-8e38-c149aa4a6cf4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create tokenized poems\n",
        "def tokenize(poem):\n",
        "    # poem_tokenize = [u'poem_start']\n",
        "    poem_tokenize = []\n",
        "    poem_tokenize.extend([poem[i] for i in range(0, len(poem))])\n",
        "    # poem_tokenize.append(u'poem_end')\n",
        "    return poem_tokenize\n",
        "poems_tokenize = [tokenize(poems[i]) for i in range(0, len(poems))]\n",
        "print (poems_tokenize[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEtaJRMK3kaa",
        "outputId": "4b3913fc-790e-43ca-c20a-c7b369e9996c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['秦', '川', '雄', '帝', '宅', '，', '函', '谷', '壮', '皇', '居', '。', '绮', '殿', '千', '寻', '起', '，', '离', '宫', '百', '雉', '馀', '。', '连', '薨', '遥', '接', '汉', '，', '飞', '观', '迥', '凌', '虚', '。', '云', '日', '隐', '层', '阙', '，', '风', '烟', '出', '绮', '疏', '。']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check unique characters\n",
        "len(np.unique(poems_tokenize))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ftbHSMm3oLI",
        "outputId": "b2ec1aaa-e905-4530-cbe8-981dce497117"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py:270: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ar = np.asanyarray(ar)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48611"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check number of characters in total\n",
        "sum([len(poems_tokenize[i]) for i in range(0, len(poems_tokenize))])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g86UK5LO3syW",
        "outputId": "eb326e51-e615-4029-941f-8bd1412f0c60"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3008122"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot words frequency\n",
        "tokens = [item for sublist in poems_tokenize for item in sublist]\n",
        "#lambda poems_tokenize: [item for sublist in poems_tokenize for item in sublist]\n",
        "unique_token = np.unique(tokens)\n",
        "n_unique_token = len(unique_token)\n",
        "tokens_count = []\n",
        "for i in range(0, n_unique_token):\n",
        "    tokens_count.append(tokens.count(unique_token[i]))\n",
        "#tokens.count(unique_token[0])"
      ],
      "metadata": {
        "id": "4OSGXKA83vbr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('median counts: %d ' % np.median(tokens_count))\n",
        "print ('frequency more than 20: %d' % len([tokens_count[i] for i in range(0, len(tokens_count))\n",
        "                                                                         if tokens_count[i] > 19]))\n",
        "print ('number of unique characters: %d' % n_unique_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9IP8KQ_5wSA",
        "outputId": "6190bee7-561e-48cb-d6dc-5ccc40830222"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "median counts: 27 \n",
            "frequency more than 20: 4052\n",
            "number of unique characters: 7492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "a0D6Rmbi6uPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the most common words and build index_to_word and word_to_index vectors\n",
        "index_to_word = [x[0] for x in unique_token]\n",
        "word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])"
      ],
      "metadata": {
        "id": "FopXHiTn5w8F"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the training data\n",
        "X_train = np.asarray([[word_to_index[w] for w in poem[:-1]] for poem in poems_tokenize])\n",
        "y_train = np.asarray([[word_to_index[w] for w in poem[1:]] for poem in poems_tokenize])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDsxoyZ53zI3",
        "outputId": "c7102209-b975-49c6-cf3a-da1b05ef261f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print an training data example\n",
        "x_example, y_example = X_train[17], y_train[17]\n",
        "print (\"x:\\n%s\\n%s\" % (\" \".join([index_to_word[x] for x in x_example]), x_example))\n",
        "print (\"\\ny:\\n%s\\n%s\" % (\" \".join([index_to_word[x] for x in y_example]), y_example))"
      ],
      "metadata": {
        "id": "3f0Nsz-w8Y8m",
        "outputId": "59ba6c1a-1405-4d53-8947-a0f5a8142065",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x:\n",
            "金 舆 巡 白 水 ， 玉 辇 驻 新 丰 。 纽 落 藤 披 架 ， 花 残 菊 破 丛 。 叶 铺 荒 草 蔓 ， 流 竭 半 池 空 。 纫 珮 兰 凋 径 ， 舒 圭 叶 翦 桐 。 昔 地 一 蕃 内 ， 今 宅 九 围 中 。 架 海 波 澄 镜 ， 韬 戈 器 反 农 。 八 表 文 同 轨 ， 无 劳 歌 大 风 。\n",
            "[6531, 5085, 1596, 3996, 3030, 7488, 3729, 6262, 7114, 2409, 109, 76, 4698, 5332, 5460, 2121, 2646, 7488, 5157, 2970, 5292, 4167, 99, 76, 732, 6629, 5239, 5234, 5397, 7488, 3174, 4414, 646, 3050, 4367, 76, 4681, 3771, 445, 491, 1784, 7488, 5090, 1018, 732, 4883, 2727, 76, 2459, 1021, 80, 5412, 459, 7488, 186, 1366, 135, 997, 108, 76, 2646, 3207, 3124, 3414, 6677, 7488, 6939, 2037, 963, 707, 470, 76, 441, 5671, 2386, 742, 6235, 7488, 2432, 595, 2949, 1171, 6998, 76]\n",
            "\n",
            "y:\n",
            "舆 巡 白 水 ， 玉 辇 驻 新 丰 。 纽 落 藤 披 架 ， 花 残 菊 破 丛 。 叶 铺 荒 草 蔓 ， 流 竭 半 池 空 。 纫 珮 兰 凋 径 ， 舒 圭 叶 翦 桐 。 昔 地 一 蕃 内 ， 今 宅 九 围 中 。 架 海 波 澄 镜 ， 韬 戈 器 反 农 。 八 表 文 同 轨 ， 无 劳 歌 大 风 。 主\n",
            "[5085, 1596, 3996, 3030, 7488, 3729, 6262, 7114, 2409, 109, 76, 4698, 5332, 5460, 2121, 2646, 7488, 5157, 2970, 5292, 4167, 99, 76, 732, 6629, 5239, 5234, 5397, 7488, 3174, 4414, 646, 3050, 4367, 76, 4681, 3771, 445, 491, 1784, 7488, 5090, 1018, 732, 4883, 2727, 76, 2459, 1021, 80, 5412, 459, 7488, 186, 1366, 135, 997, 108, 76, 2646, 3207, 3124, 3414, 6677, 7488, 6939, 2037, 963, 707, 470, 76, 441, 5671, 2386, 742, 6235, 7488, 2432, 595, 2949, 1171, 6998, 76, 117]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save training data\n",
        "pickle.dump((X_train, y_train, index_to_word, word_to_index), open('trainingData.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "nStnnpj48gx1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models        import Sequential\n",
        "from keras.layers        import Input, Dense, Dropout\n",
        "from keras.layers        import Embedding\n",
        "from keras.layers        import LSTM\n",
        "from keras               import backend as K\n",
        "from keras.preprocessing import sequence\n",
        "import tensorflow as tf\n",
        "\n",
        "import pickle\n",
        "import numpy      as np"
      ],
      "metadata": {
        "id": "EgP3-tI58mz1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cores = 1\n",
        "num_CPU = 1\n",
        "num_GPU = 0\n",
        "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=num_cores,\\\n",
        "        inter_op_parallelism_threads=num_cores, allow_soft_placement=True,\\\n",
        "        device_count = {'CPU' : num_CPU, 'GPU' : num_GPU})\n",
        "sess = tf.compat.v1.Session(config=config)\n",
        "K.set_session(sess)"
      ],
      "metadata": {
        "id": "JvezgfRf9NzW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "metadata": {
        "id": "e6W-1m1q9Qz8",
        "outputId": "58c3ad23-4fe9-4dad-9ddb-22c38dd636b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 3193287520307353226\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14465892352\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 8491152162560779012\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 1024"
      ],
      "metadata": {
        "id": "eP29Re9vCr7O"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, index_to_word, word_to_index = pickle.load(open('trainingData.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "IX3EqI2HCu8Q"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('X_train shape: {}, Y_train shape: {}'.format(X_train.shape, y_train.shape))"
      ],
      "metadata": {
        "id": "-XD8yczuCw8n",
        "outputId": "e210b984-b2a1-46f1-dcde-f845d547f5d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (48975,), Y_train shape: (48975,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])\n",
        "print(y_train[0])\n",
        "print(index_to_word[0:10])\n",
        "print(list(word_to_index.keys())[0:10])"
      ],
      "metadata": {
        "id": "SX68bGxZCy7G",
        "outputId": "59575e35-d6a4-4fb3-cb03-1825ec34d0c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4317, 1594, 6824, 1632, 1366, 7488, 511, 5967, 1153, 4001, 1456, 76, 4742, 2986, 642, 1426, 6078, 7488, 4299, 1391, 3997, 6828, 7056, 76, 6310, 5442, 6379, 2234, 3038, 7488, 7010, 5777, 6314, 492, 5486, 76, 152, 2434, 6803, 1454, 6746, 7488, 6998, 3516, 509, 4742, 3918]\n",
            "[1594, 6824, 1632, 1366, 7488, 511, 5967, 1153, 4001, 1456, 76, 4742, 2986, 642, 1426, 6078, 7488, 4299, 1391, 3997, 6828, 7056, 76, 6310, 5442, 6379, 2234, 3038, 7488, 7010, 5777, 6314, 492, 5486, 76, 152, 2434, 6803, 1454, 6746, 7488, 6998, 3516, 509, 4742, 3918, 76]\n",
            "[' ', '(', ')', ',', '-', '.', '0', '1', '2', '3']\n",
            "[' ', '(', ')', ',', '-', '.', '0', '1', '2', '3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_characters = sorted(list(word_to_index))\n",
        "target_characters = sorted(list(word_to_index))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in X_train])\n",
        "max_decoder_seq_length = max([len(txt) for txt in y_train])\n",
        "\n",
        "print('Number of samples:', len(X_train))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)"
      ],
      "metadata": {
        "id": "u0XjEIUGC1SC",
        "outputId": "92371f98-5a79-454b-f71b-63bdcffc0d7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 48975\n",
            "Number of unique input tokens: 7492\n",
            "Number of unique output tokens: 7492\n",
            "Max sequence length for inputs: 2445\n",
            "Max sequence length for outputs: 2445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models        import Sequential\n",
        "from keras.layers        import Input, Dense, Dropout\n",
        "from keras.layers        import Embedding\n",
        "from keras.layers        import LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras               import backend as K\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "import random"
      ],
      "metadata": {
        "id": "bGlc76TsC-iB"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model: a single LSTM\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "maxlen =1000\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(input_characters))))\n",
        "model.add(Dense(len(input_characters), activation='softmax'))\n",
        "\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "metadata": {
        "id": "rID1jVEWDAue",
        "outputId": "72fd05bc-a957-4406-a39d-1b8841d90b08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "id": "gKQzT221DQAF",
        "outputId": "03b5a6e7-3039-48d7-b21c-e0458193f37b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               3901952   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 7492)              966468    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,868,420\n",
            "Trainable params: 4,868,420\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models        import Sequential\n",
        "from keras.layers        import Input, Dense, Dropout\n",
        "from keras.layers        import Embedding\n",
        "from keras.layers        import LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras               import backend as K\n",
        "from keras.preprocessing import sequence\n",
        "import tensorflow as tf\n",
        "\n",
        "import random\n",
        "import pickle\n",
        "import numpy      as np"
      ],
      "metadata": {
        "id": "FdgeXFK6EBjZ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 40\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "bzNFiqY3EFJH"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After load data\n",
        "class DataGenerator(keras.utils.all_utils.Sequence):\n",
        "    \"\"\"Generates data for Keras.\"\"\"\n",
        "    def __init__(self, X_train=X_train, y_train=y_train, maxlen=maxlen, n_classes=len(input_characters), shuffle=True, \n",
        "                batch_size=batch_size):\n",
        "        \"\"\"Initialization.\n",
        "        \n",
        "        Args:\n",
        "        \"\"\"\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.maxlen = maxlen\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.batch_size = batch_size\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Denotes the number of batches per epoch.\"\"\"\n",
        "        return int(np.floor(len(self.X_train) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Generate one batch of data.\"\"\"\n",
        "        # Randomly sample a sentence length\n",
        "        sentence_length = np.random.randint(self.maxlen - 1) + 1  # Guarantee pick at least 1 word\n",
        "        \n",
        "        x = []\n",
        "        y = []\n",
        "        for n in range(self.batch_size):\n",
        "            # Randomly sample a poem\n",
        "            poem_id = np.random.randint(len(self.X_train))\n",
        "            poem = self.X_train[poem_id]\n",
        "            \n",
        "            # Create sentence and next_char\n",
        "            sentence = poem[0:sentence_length]\n",
        "            \n",
        "            # Vectorize\n",
        "            x_temp = np.zeros((sentence_length, self.n_classes))\n",
        "            y_temp = np.zeros(self.n_classes)\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_temp[t, char] = 1\n",
        "            if len(self.y_train[poem_id]) >= sentence_length:\n",
        "                y_temp[self.y_train[poem_id][sentence_length - 1]] = 1\n",
        "            else:\n",
        "                y_temp[5] = 1  # Mark as \".\"\n",
        "            x.append(x_temp)\n",
        "            y.append(y_temp)\n",
        "        \n",
        "        X = np.array(x, dtype=np.bool)\n",
        "        y = np.array(y, dtype=np.bool)\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch.\"\"\"\n",
        "        # self.indexes = np.arange(len(self.img_files))\n",
        "        # if self.shuffle == True:\n",
        "        #    np.random.shuffle(self.indexes)\n",
        "        pass\n",
        "    \n",
        "train_datagen = DataGenerator()"
      ],
      "metadata": {
        "id": "HYUX2bQgELau"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model: a single LSTM\n",
        "print('Build model...')\n",
        "model2 = Sequential()\n",
        "model2.add(LSTM(128, input_shape=(None, len(input_characters))))\n",
        "model2.add(Dense(len(input_characters), activation='softmax'))\n",
        "\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model2.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "print(model2.summary())"
      ],
      "metadata": {
        "id": "FqIcxF_KEOoY",
        "outputId": "d42622b8-121a-470e-e1ca-375c825bd234",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build model...\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_1 (LSTM)               (None, 128)               3901952   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7492)              966468    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,868,420\n",
            "Trainable params: 4,868,420\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def on_epoch_end2(epoch, _, input_sentence=\"风停\", temperature=1.3, maxlen=40):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    # Recurrent for maxlen\n",
        "    cur_len = len(input_sentence)\n",
        "\n",
        "    # Initiate\n",
        "    input_x_index = [word_to_index[i] for i in input_sentence]\n",
        "    input_x = np.zeros((1, maxlen, len(input_characters)))\n",
        "    for i, index in enumerate(input_x_index):\n",
        "        input_x[0, i, index] = 1\n",
        "\n",
        "    while cur_len < maxlen:\n",
        "        preds = model2.predict(input_x[:, 0:cur_len, :], verbose=0)[0]\n",
        "        next_index = sample(preds, temperature)\n",
        "        next_char = index_to_word[next_index]\n",
        "        input_sentence += next_char\n",
        "        input_x[0, cur_len, next_index] = 1\n",
        "        cur_len += 1\n",
        "        \n",
        "    print(\"Epoch {}, output: {}\".format(epoch, input_sentence))\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end2)\n",
        "\n",
        "# model2.fit(x, y,\n",
        "#           batch_size=128,\n",
        "#           epochs=1,\n",
        "#           callbacks=[print_callback])\n",
        "model2.fit_generator(train_datagen, epochs=100, use_multiprocessing=True, verbose=1, \n",
        "                    callbacks=[print_callback])\n",
        "\n",
        "# model2.save(\"40_words.h5\")"
      ],
      "metadata": {
        "id": "fcet2gDLEcWC",
        "outputId": "65a965e1-40ad-4f0b-ea9e-6fcb1f45d698",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 6.4834Epoch 0, output: 风停萋歌疥三荐摹传倏时秦愁.开空消-将雇憨总诗，烘翔坞夜自钩，声室洲云径。官凋砧\n",
            "382/382 [==============================] - 59s 138ms/step - loss: 6.4851\n",
            "Epoch 2/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.9189Epoch 1, output: 风停穿阳调上几鹤h古鬝亦玙...........................\n",
            "382/382 [==============================] - 49s 129ms/step - loss: 5.9189\n",
            "Epoch 3/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.5397Epoch 2, output: 风停语共况宰都共临奉有客土联阶取砧扫终夏堂里和人掩B定波讴触泥飞南节应.群眠亦定\n",
            "382/382 [==============================] - 50s 129ms/step - loss: 5.5434\n",
            "Epoch 4/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.5634Epoch 3, output: 风停于萦镜瑟看，眼。问此诗长今盛紫。归柳时夜桥把筝，童楼杖烟静当活。凋草.伴晓手\n",
            "382/382 [==============================] - 51s 134ms/step - loss: 5.5634\n",
            "Epoch 5/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.5466Epoch 4, output: 风停此南毫地烟惊银榆意，枝年径南人文云心井初晚花□七镜愁新银叶，四半馆苍静知过，\n",
            "382/382 [==============================] - 51s 134ms/step - loss: 5.5466\n",
            "Epoch 6/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.6181Epoch 5, output: 风停暮中醉坐影，上雾卫中侣早.。流念我三李菘衣还惭服，隔以如，汀轻须并心光不，邻\n",
            "382/382 [==============================] - 48s 126ms/step - loss: 5.6181\n",
            "Epoch 7/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.5958Epoch 6, output: 风停遥锁纱身飞，看花居萝山风芳长翠馀语狂是。是折怀使江上楼，不禁玉窗岳人十，，桂\n",
            "382/382 [==============================] - 50s 129ms/step - loss: 5.5958\n",
            "Epoch 8/100\n",
            "380/382 [============================>.] - ETA: 0s - loss: 5.6287Epoch 7, output: 风停曙越会荒深，穷路年。不紫地。万年传命应席游，影鸾途乱照高萍。水作东景与尘羡，\n",
            "382/382 [==============================] - 50s 130ms/step - loss: 5.6275\n",
            "Epoch 9/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.6326Epoch 8, output: 风停荷应早，风塘还复北。爱方搜中来，十海。夜红近茅酒里寒，歌吟曲危燕生时，徒信君\n",
            "382/382 [==============================] - 51s 134ms/step - loss: 5.6243\n",
            "Epoch 10/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.5248Epoch 9, output: 风停早暖残高在，陵与池轩尽夜深。寻来爱树乘况西，野路北溪望月吹。疏筵娇，房落日，\n",
            "382/382 [==============================] - 50s 130ms/step - loss: 5.5248\n",
            "Epoch 11/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.2404Epoch 10, output: 风停露流酣似千，夜雨水天春晚空。黄金山恨尽不起，寒天照雪息，钓念香隐上，终爱千潭\n",
            "382/382 [==============================] - 51s 132ms/step - loss: 5.2404\n",
            "Epoch 12/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.4429Epoch 11, output: 风停悲说古啼亲，病此行看月到地为........................\n",
            "382/382 [==============================] - 51s 133ms/step - loss: 5.4429\n",
            "Epoch 13/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.3527Epoch 12, output: 风停花军映霞兮雏滴仙，壁满生香旟不知。平开孤祭盈随雾，与成当国君阳峡。有旌稀，茶\n",
            "382/382 [==============================] - 51s 132ms/step - loss: 5.3527\n",
            "Epoch 14/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.5463Epoch 13, output: 风停石下发，晚引应禅鹤。壁得扫风夏，几多闲好艳。别天兵相未疑夜，亭暮玄薄夏宾寒，\n",
            "382/382 [==============================] - 46s 120ms/step - loss: 5.5463\n",
            "Epoch 15/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.2807Epoch 14, output: 风停摇心吹鸥归，道来新影偷吹符。华上到兰球古寺，秋蝉拂鹤侵中波。全溪长翠见碧下川\n",
            "382/382 [==============================] - 50s 132ms/step - loss: 5.2807\n",
            "Epoch 16/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.3829Epoch 15, output: 风停游寒第兴台，暮朝观镜望无声。沙愧波履宿章流意虽骑人间寄见童当正堕以千歌得平逢\n",
            "382/382 [==============================] - 48s 126ms/step - loss: 5.3829\n",
            "Epoch 17/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.2260Epoch 16, output: 风停是共王，所以渐药内。南远同非心，（闻军南景门前。南宾圆月长安洞，平白疾兴颜时\n",
            "382/382 [==============================] - 48s 125ms/step - loss: 5.2260\n",
            "Epoch 18/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.3006Epoch 17, output: 风停横地火，极气百孤寒。白鹤路先与烛新。泪绕宾衣下月华，性驱佳人主里夜。谁间微天\n",
            "382/382 [==============================] - 50s 129ms/step - loss: 5.3006\n",
            "Epoch 19/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.2956Epoch 18, output: 风停离歌落透出，本取桥声属有情。爽萝因悲州柳井，唯有才自属身幽。晴流坐后蜀天寒，\n",
            "382/382 [==============================] - 50s 130ms/step - loss: 5.2956\n",
            "Epoch 20/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.4821Epoch 19, output: 风停还前处，朝前计问开。徒游近过口，须尽我物方平。相逢玉念疏羊地，柳叶女寒飞作下\n",
            "382/382 [==============================] - 49s 127ms/step - loss: 5.4821\n",
            "Epoch 21/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.2412Epoch 20, output: 风停东露拂夫头，红叶先歌雪宫斜。碧静新无画白对，得消烟栽树苑孤。满更启边连不渚，\n",
            "382/382 [==============================] - 49s 127ms/step - loss: 5.2358\n",
            "Epoch 22/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.2614Epoch 21, output: 风停数杯赏，凉下鹤在浦。泽王船南鹭七曲，笔名海色去难游。风名士子渡烟尘，情水书牛\n",
            "382/382 [==============================] - 51s 133ms/step - loss: 5.2671\n",
            "Epoch 23/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.3679Epoch 22, output: 风停旧物襟清声。谁知无地，暑鱼目待，万里一神。八更见鸦，好逢君美有。门歌莫曲，愁\n",
            "382/382 [==============================] - 51s 133ms/step - loss: 5.3679\n",
            "Epoch 24/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.3945Epoch 23, output: 风停去门楚郡，畔虎林园有抱。怜君君莫恐相逢，路接独无思此事，岸夕来去两杜陵。晓烟\n",
            "382/382 [==============================] - 52s 135ms/step - loss: 5.3945\n",
            "Epoch 25/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.2430Epoch 24, output: 风停舞闺雪残春，春思鱼龙句起客。千里女云老化天，却花庭白后池行。北外暮期长恨绝，\n",
            "382/382 [==============================] - 49s 128ms/step - loss: 5.2430\n",
            "Epoch 26/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.2666Epoch 25, output: 风停朝年暖，笙歌弄依依。掩瘴回头竹，人少虚船瀛。洛城先南能看步，半似凡月最高方。\n",
            "382/382 [==============================] - 51s 132ms/step - loss: 5.2666\n",
            "Epoch 27/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.2112Epoch 26, output: 风停酒扑暖，黄云夕夕成。已斜已盛远，忍此惜心如。古面同人在，禄合独自愁。秋风吹露\n",
            "382/382 [==============================] - 51s 132ms/step - loss: 5.2178\n",
            "Epoch 28/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.2418Epoch 27, output: 风停晴清簟立凄，是时苗把分人别，今日时来卧，应边烟边曲。主客阴还望，十二守方新。\n",
            "382/382 [==============================] - 51s 133ms/step - loss: 5.2418\n",
            "Epoch 29/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.3078Epoch 28, output: 风停入罗歌已深，虎州双爱使乡人迟。不还当谢入山台。心之寒图篇明明，万里隔舟望潮天\n",
            "382/382 [==============================] - 50s 129ms/step - loss: 5.3078\n",
            "Epoch 30/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.1561Epoch 29, output: 风停顷潭德，新帝离条州。舞色迷久密，儿幕未还亲。雨馀秋色浅，春来暮巷半。白头经万\n",
            "382/382 [==============================] - 50s 131ms/step - loss: 5.1561\n",
            "Epoch 31/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.3141Epoch 30, output: 风停犹相火，天入暮百江。观上人已至，万年今物月。生叹山妒命声事，待赠凌烟塞里月。\n",
            "382/382 [==============================] - 51s 133ms/step - loss: 5.3191\n",
            "Epoch 32/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.2125Epoch 31, output: 风停空烟叶，看公异年书。贤人出深处，青门自自稀。已兵飞帝归，若得太张丝。数钱时江\n",
            "382/382 [==============================] - 51s 131ms/step - loss: 5.2059\n",
            "Epoch 33/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.3884Epoch 32, output: 风停趋散向重消，更有红君道几时。齐乱开轩凝半机，花开荷石低难开。艳深知有僧成客，\n",
            "382/382 [==============================] - 51s 132ms/step - loss: 5.3898\n",
            "Epoch 34/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.1438Epoch 33, output: 风停柳曲摇来尽，殷勤十翔共离鸾。泪滴一春风韶霜，思落晴烟萧索梧窗上飞移院早看山亦\n",
            "382/382 [==============================] - 52s 135ms/step - loss: 5.1438\n",
            "Epoch 35/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.2094Epoch 34, output: 风停鸣露曲，谢曲非空邦。南顾才常少，教力雁惆辰。朝头辞非人，珮以如是耳。主带林间\n",
            "382/382 [==============================] - 52s 135ms/step - loss: 5.2094\n",
            "Epoch 36/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.3207Epoch 35, output: 风停秋思暗东风醉号西郭已寒凋，但从朱鼓未冠容。石湖静里飞还发，新闻声名谁似空。故\n",
            "382/382 [==============================] - 50s 129ms/step - loss: 5.3207\n",
            "Epoch 37/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.2988Epoch 36, output: 风停城临寺，梅鹤有霞入。报口风不自，终乐尽怨蝉。客少还藏尽，胡笳急鸯出。见树踏客\n",
            "382/382 [==============================] - 48s 127ms/step - loss: 5.3015\n",
            "Epoch 38/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.1817Epoch 37, output: 风停径用子，出鸟尺冠衣。马蹄潜侠游，马听鸡犬摇。唯有败关来，秋风亦畏无家樽以既应\n",
            "382/382 [==============================] - 53s 137ms/step - loss: 5.1817\n",
            "Epoch 39/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.2308Epoch 38, output: 风停故乡户，干烟起在居。主船分断载，年少安斋时。临水近青岭。天气绕春叠，山川标暮\n",
            "382/382 [==============================] - 52s 135ms/step - loss: 5.2308\n",
            "Epoch 40/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.1393Epoch 39, output: 风停晓影卷霜屋，妾题心种清生多来。近途吹影传松山馀老川院被二金牵挂剑随悬叹帝门空\n",
            "382/382 [==============================] - 52s 134ms/step - loss: 5.1361\n",
            "Epoch 41/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.2989Epoch 40, output: 风停试看作花杯，入骨何时啼风秋。一去已喧昭有宅，东山桃李洛花秋。塞柳沙河是陇头，\n",
            "382/382 [==============================] - 51s 133ms/step - loss: 5.2989\n",
            "Epoch 42/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.2516Epoch 41, output: 风停竹枝水，白日覆寒河。独立依林下，色无吹碧画，今见昔时船。莫典迟何事，墙归旧长\n",
            "382/382 [==============================] - 49s 127ms/step - loss: 5.2470\n",
            "Epoch 43/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.4258Epoch 42, output: 风停回望日，江波正滨前。客堪怜我去，马我去时公。扫阁怜无愿，遗清意童稚。万人弃何\n",
            "382/382 [==============================] - 50s 130ms/step - loss: 5.4258\n",
            "Epoch 44/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.3464Epoch 43, output: 风停谁走高起经，听月一将一夕阳。岸何有时明月岸，朱袍珠帘到影阴。冰贫极食人埃树，\n",
            "382/382 [==============================] - 52s 134ms/step - loss: 5.3464\n",
            "Epoch 45/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.3734Epoch 44, output: 风停父魄化边吟，霜霰明堂堂落难。行回明，京错过。，小鸡神灰。池流落落，枝晴斯媚晖\n",
            "382/382 [==============================] - 49s 129ms/step - loss: 5.3734\n",
            "Epoch 46/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.5081Epoch 45, output: 风停九华雪梅明，半夜深融双鬟过，大宅发处眠幽人。凋寒扬，懒晚草，满营经风青芦碛。\n",
            "382/382 [==============================] - 50s 130ms/step - loss: 5.5139\n",
            "Epoch 47/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.4920Epoch 46, output: 风停鱼龙杨梁台。气似秋华发始弹，远寻兴宴馀秋借。华前芳草高尘。星分绣电参差莲，笑\n",
            "382/382 [==============================] - 49s 127ms/step - loss: 5.4944\n",
            "Epoch 48/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.5473Epoch 47, output: 风停只月鸣鸿声，今日休空漏不传。地深红花正千朝吴歌朝夕收灯烛，罗碧红阑压向尘。儿\n",
            "382/382 [==============================] - 50s 130ms/step - loss: 5.5473\n",
            "Epoch 49/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.3893Epoch 48, output: 风停心外起，繁暑落花红。小职思门里，闲听妇意长。酒寝辞休宫，鞍马子酣歌。别意来欢\n",
            "382/382 [==============================] - 50s 131ms/step - loss: 5.3893\n",
            "Epoch 50/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.4473Epoch 49, output: 风停杏浸开避绿，正对清明门下处。中子定闻将死分，可怜同旅独然成。紫角来将乐千国，\n",
            "382/382 [==============================] - 49s 128ms/step - loss: 5.4473\n",
            "Epoch 51/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.3214Epoch 50, output: 风停碎角景，树叶长含宫。嶂上含临语，明月正华池。天生喧绝岸，身马与门人。主人雕.\n",
            "382/382 [==============================] - 49s 127ms/step - loss: 5.3214\n",
            "Epoch 52/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.5500Epoch 51, output: 风停宿露立飘眉。夜照仙州碧窗对，暮水朱边有路何。家掌满鱼重锦里，外其陈德日高冠。\n",
            "382/382 [==============================] - 48s 125ms/step - loss: 5.5500\n",
            "Epoch 53/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.5727Epoch 52, output: 风停独未寺。珠萼似灯闹，石空折青云。九重分直作，近策最高虚。仙气盛高酒，过金锁子\n",
            "382/382 [==============================] - 49s 129ms/step - loss: 5.5760\n",
            "Epoch 54/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.6058Epoch 53, output: 风停帘外动门枝，章句七条月霜堂。将上不见星覆晓，岁花有辙千条子，金藨崩示自柔足。\n",
            "382/382 [==============================] - 48s 125ms/step - loss: 5.6058\n",
            "Epoch 55/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.4626Epoch 54, output: 风停杜林密，炉香出小谁。谁今孤客伴，千绣度方春。旧信自经石，翠若鹤独寒。神庭明十\n",
            "382/382 [==============================] - 51s 134ms/step - loss: 5.4633\n",
            "Epoch 56/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.3400Epoch 55, output: 风停舟行动满台。教下分明含月色，定知危羽别离人。云诗丽性金境尽，箫鼓雁违陶姓名。\n",
            "382/382 [==============================] - 53s 139ms/step - loss: 5.3400\n",
            "Epoch 57/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.3814Epoch 56, output: 风停秋光薄，澄洲江岛然。小岳人未阔，今夜见云台。岂知皆如往，一淋陶司吏。朔鞴草萦\n",
            "382/382 [==============================] - 50s 131ms/step - loss: 5.3817\n",
            "Epoch 58/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.6333Epoch 57, output: 风停舟声名，犹知书得闲。累深山府道，力道来亲霞。微然老懒新，大素来倾吟。问书归信\n",
            "382/382 [==============================] - 52s 134ms/step - loss: 5.6370\n",
            "Epoch 59/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.6539Epoch 58, output: 风停寻吹雏。低买罗锦眉，笙歌舞车迟。腰作蕙鸿丝，七凤是抽箫。西声不宇前酒杯，舞怨\n",
            "382/382 [==============================] - 51s 132ms/step - loss: 5.6539\n",
            "Epoch 60/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.5564Epoch 59, output: 风停牵夸车，疑是妾来时。萧条青琴尊，一思与常迟。江好隔蜀袖，世禄能论陈。岂为露木\n",
            "382/382 [==============================] - 51s 132ms/step - loss: 5.5564\n",
            "Epoch 61/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.5392Epoch 60, output: 风停独坐寂安清，夜半朝暗澹莺啼。阶名晚泊随花圣，今见吴王直路遥。（历宫日几度空陵\n",
            "382/382 [==============================] - 49s 129ms/step - loss: 5.5392\n",
            "Epoch 62/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.6245Epoch 61, output: 风停积寒切积寒红烛深纱窗户，窗上床就玉壶蜂。石香风月半沈梧，落风初歇最相投。机间\n",
            "382/382 [==============================] - 48s 126ms/step - loss: 5.6245\n",
            "Epoch 63/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.5663Epoch 62, output: 风停春愁听黄帆，君惟应鞭忽似功。松鸟爱时多此灰，闲闲还石广山淹。经才共泪孤烧开，\n",
            "382/382 [==============================] - 52s 136ms/step - loss: 5.5663\n",
            "Epoch 64/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.4768Epoch 63, output: 风停尊月有期深，净华金空故未前，杜鹃无能照风迟。谩幸在布归共疾，近经平楚帝王心。\n",
            "382/382 [==============================] - 51s 131ms/step - loss: 5.4768\n",
            "Epoch 65/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.5841Epoch 64, output: 风停水宿今愿依，在今逢往几时飞。亭前客转微无起，便上清残一玉净。可独斜日见难衣，\n",
            "382/382 [==============================] - 51s 133ms/step - loss: 5.5841\n",
            "Epoch 66/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.4159Epoch 65, output: 风停春欲尽外言，何守疏芳一谁寒。台谷下仙峰，近山正见松。香看谁劝，暮清雁尽丝一醉\n",
            "382/382 [==============================] - 51s 133ms/step - loss: 5.4159\n",
            "Epoch 67/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.2149Epoch 66, output: 风停双月且城时，，雨吞那道。思君易玉，四顾河上。香望易惆，送桂题花。夜和白云外，\n",
            "382/382 [==============================] - 52s 136ms/step - loss: 5.2149\n",
            "Epoch 68/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.4422Epoch 67, output: 风停怀切切，岩外倚烟水。诗点秦僧树二衢，客船还如镜。云从久渐转，堪问远经宫。石掩\n",
            "382/382 [==============================] - 52s 136ms/step - loss: 5.4422\n",
            "Epoch 69/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.3224Epoch 68, output: 风停声高促，松宛懒系州。寂寞纷纷月，霜天色隔长。夜虚风梦处，漏入哭通洲。雾流许晓\n",
            "382/382 [==============================] - 51s 134ms/step - loss: 5.3224\n",
            "Epoch 70/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.3932Epoch 69, output: 风停池外入幽居，五年一自一宵团。齐剑篙竹氛竹此，压沉沉沉沉入仙微迹。大心从此东还\n",
            "382/382 [==============================] - 52s 136ms/step - loss: 5.3932\n",
            "Epoch 71/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.4377Epoch 70, output: 风停不及道，骨拂垂白杨。乐罢不如背，干非小已开。雨滴云古棹，九峰振危禅。曲省兰苏\n",
            "382/382 [==============================] - 51s 133ms/step - loss: 5.4377\n",
            "Epoch 72/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.5001Epoch 71, output: 风停沧洲雁，帆帆引上堤。半霜愁独宿，远客欲栖栖，风惊树隔秋思罗。欲暮春行魂，如伤\n",
            "382/382 [==============================] - 49s 127ms/step - loss: 5.5001\n",
            "Epoch 73/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.3615Epoch 72, output: 风停翠帘香一纱，却对谁能出碧明。白素一生成剑发，各应吹凤剑沉沉。金坛头发黄条箕，\n",
            "382/382 [==============================] - 50s 129ms/step - loss: 5.3554\n",
            "Epoch 74/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.4579Epoch 73, output: 风停泛暮鸟相逢，水傍莲衣不有馀。水外玉天台下澄，剪花已落两无匀。才当暖足耕金家，\n",
            "382/382 [==============================] - 51s 132ms/step - loss: 5.4579\n",
            "Epoch 75/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.4167Epoch 74, output: 风停清夜卧闻壶，四望通江上雪书。童湿常无教若稍，笑边秋水到珠阶。都床坐见春终老，\n",
            "382/382 [==============================] - 52s 135ms/step - loss: 5.4167\n",
            "Epoch 76/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.3083Epoch 75, output: 风停雨影动嵩亭，今物游经久姓名。有岸丹霄通帝图春新陌碍冷梅香近，绿色晴开暮四楼。\n",
            "382/382 [==============================] - 51s 133ms/step - loss: 5.3083\n",
            "Epoch 77/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.2438Epoch 76, output: 风停春风偶别愁，高中香语泪垆回。花华寂寂歌惊宿，重溪更古随风看。重从小日归人远，\n",
            "382/382 [==============================] - 51s 133ms/step - loss: 5.2438\n",
            "Epoch 78/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.6942Epoch 77, output: 风停春风急，平明何处归。时灯秋远瑞，吾君日时成。可得多云空，何然何容开。谁孙名添\n",
            "382/382 [==============================] - 49s 127ms/step - loss: 5.6942\n",
            "Epoch 79/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.5769Epoch 78, output: 风停不禁薄，三户雪洲起。（列得子路家所带家，大方独石子潇湘。听神家建章年殿，名旅\n",
            "382/382 [==============================] - 50s 129ms/step - loss: 5.5773\n",
            "Epoch 80/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.4865Epoch 79, output: 风停蒲车晚复悲，数年同入夜来年。浮华弄此惊尘柱阁渡眉方浩浩为飞霜雪涛霜雪为安灵远\n",
            "382/382 [==============================] - 51s 132ms/step - loss: 5.4829\n",
            "Epoch 81/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.4695Epoch 80, output: 风停竹合，湘谷分明。此心香中促，转几时行五时。斋似陈恨已还明，秋磬烟晦几东峰。古\n",
            "382/382 [==============================] - 52s 136ms/step - loss: 5.4695\n",
            "Epoch 82/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.4680Epoch 81, output: 风停杨柳絮连迟，香想时泷南国遥。今不无人计多衮，禅题松竹挂归山。鸿雁应随过客卧。\n",
            "382/382 [==============================] - 51s 134ms/step - loss: 5.4680\n",
            "Epoch 83/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.5598Epoch 82, output: 风停宫槐雨露金，小山芦悴深多居。清阴纹夜更初随，鹤似西条一廥景。物中推平早初昏。\n",
            "382/382 [==============================] - 51s 134ms/step - loss: 5.5598\n",
            "Epoch 84/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.5523Epoch 83, output: 风停春心曲，莺声挂舞衣。低声留清唱，布衣白雪侵。彩缨长含德，始悲遍塞雨。雾引飞飞\n",
            "382/382 [==============================] - 51s 133ms/step - loss: 5.5523\n",
            "Epoch 85/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.7120Epoch 84, output: 风停清历帘待月，碧山飘意不任饮。刘圃红树孤坟白，上白犹自失岸语。枕前子寒燕须腰，\n",
            "382/382 [==============================] - 51s 132ms/step - loss: 5.7120\n",
            "Epoch 86/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.6170Epoch 85, output: 风停题子鬓，好步戏离骚。欲结何，班，名子石，坐尽守同闲。堪闲处，寻山静，野径枝叶\n",
            "382/382 [==============================] - 50s 132ms/step - loss: 5.6127\n",
            "Epoch 87/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.6032Epoch 86, output: 风停盈月韵，床畔竹堂离。四冷闲初叶，成名记更乡。有声有林湿，白木带星时。烛女云，\n",
            "382/382 [==============================] - 52s 135ms/step - loss: 5.6032\n",
            "Epoch 88/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.6879Epoch 87, output: 风停偏已伴，阴人惜远虫。襄阳漠漠尽不迷，未有香处谢。放驾和风吹，缘山入紫芝。鸣机\n",
            "382/382 [==============================] - 51s 133ms/step - loss: 5.6879\n",
            "Epoch 89/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.6834Epoch 88, output: 风停春去金华筵，记得开华新片光。将步闲生细浪上，三干六月愁空谙。秋间一日照光发，\n",
            "382/382 [==============================] - 52s 134ms/step - loss: 5.6834\n",
            "Epoch 90/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.7053Epoch 89, output: 风停因他日，离容真世路。星鸣息酒醒，风卷望南间。九落丹加别，楼台掩扉枝。一花云剑\n",
            "382/382 [==============================] - 50s 130ms/step - loss: 5.7053\n",
            "Epoch 91/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 6.3165Epoch 90, output: 风停裁晴照竹玉。紫鸯晚泊为画耕，村开青巷绕吟空，野中空庭唯带鸟，十年起在河尽身，\n",
            "382/382 [==============================] - 53s 137ms/step - loss: 6.3165\n",
            "Epoch 92/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.6666Epoch 91, output: 风停共起洞庭新，双锁潇湘入东林。出碧风山月照耀，满阶行路一泠泠。破堂朝为鹤吹迸，\n",
            "382/382 [==============================] - 53s 136ms/step - loss: 5.6740\n",
            "Epoch 93/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 5.7550Epoch 92, output: 风停满目秋灯坐深巷满堂，紫绶轻沈醉席满。花如任鸟虽谁了，其在只悲数杯中。艳阳明公\n",
            "382/382 [==============================] - 52s 135ms/step - loss: 5.7550\n",
            "Epoch 94/100\n",
            "381/382 [============================>.] - ETA: 0s - loss: 5.5780Epoch 93, output: 风停若惊飞二剑，暂胜鸳鹭向南峰。西陵病卧种诗伦，吴屋当回欲共榛。五六时还长细去，\n",
            "382/382 [==============================] - 53s 137ms/step - loss: 5.5852\n",
            "Epoch 95/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 9.9398Epoch 94, output: 风停声处看，昨关南冥儒懒。眇街还州出，赤夫鹉泪弦，还泊。四犹有时知。遇寺。锦色，\n",
            "382/382 [==============================] - 51s 134ms/step - loss: 9.9398\n",
            "Epoch 96/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 11.5165Epoch 95, output: 风停芙蓉栽临片雨看林晚。招县旧潮衾晨怜清条。清修小手桥万头年草生。年栏事城遥入。\n",
            "382/382 [==============================] - 52s 135ms/step - loss: 11.5165\n",
            "Epoch 97/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 10.1643Epoch 96, output: 风停谁长宴开.生，金茶人中袅，常暂.灵好绿烟尽梦寒里夜泥书亦事闲酒唯。东开，一极\n",
            "382/382 [==============================] - 52s 135ms/step - loss: 10.1643\n",
            "Epoch 98/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 10.0350Epoch 97, output: 风停城声。车欲敢行家蛾美钗印悬红砌深漏芳华笛眉回移皇朝迎日文遥辉馀华亭睡仙双英中\n",
            "382/382 [==============================] - 50s 130ms/step - loss: 10.0350\n",
            "Epoch 99/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 9.8929Epoch 98, output: 风停同旬游长只明亲达诗无上，而孙恨今雪人-面身看中韵，人空影，清庭.画乍.日庭帘\n",
            "382/382 [==============================] - 52s 137ms/step - loss: 9.8929\n",
            "Epoch 100/100\n",
            "382/382 [==============================] - ETA: 0s - loss: 10.2260Epoch 99, output: 风停行鸥木而浮德师危书吟嗟岁常欲谁结闲心何处迷贤意成为路海禅车尘溪分头明何四，帝\n",
            "382/382 [==============================] - 50s 132ms/step - loss: 10.2260\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2fb5076850>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f2PThzoaEfw-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}